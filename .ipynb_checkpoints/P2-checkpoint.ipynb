{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Packages required\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from collections import deque\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Calibration\n",
    "\n",
    "To be calibrate camera we'll use photos of chessboards. By using **cv2.findChessboardCorners** we will find out coordinates of chessboard corners in the image. Then we will create mapping for those points in real 3D space using **np.mgrid**. Then by using image point and object point mappings we will calculate camera matrix and distortion co-efficients by using **cv2.calibrateCamera**. Now we can undistort any image captured by the same camera that took calibration images, by using **cv2.undistort**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Camera Calibration\n",
    "\n",
    "x, y = 9,6   # Dimention of the chessboards to look into calibration images\n",
    "image_points = []\n",
    "\n",
    "for calibration_image in glob('camera_cal/calibration*.jpg'):\n",
    "    img = mpimg.imread(calibration_image)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # calculating coordinates of chessboard corners in the image\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (x,y), None)\n",
    "    if ret: image_points.append(corners)\n",
    "\n",
    "# Preparing corrdinates of chessboard corners in 3D space         \n",
    "object_points = [np.mgrid[:x,:y,:1].T.reshape(-1,3).astype(np.float32)]*len(image_points)\n",
    "\n",
    "# calculating camera matrix and distortion co-efficients using cv2.calibrateCamera\n",
    "ret, camera_matrix, distortion_coeffs, _, _ = cv2.calibrateCamera(object_points, image_points, gray.shape, None, None)\n",
    "\n",
    "def undistort(img, camera_matrix = camera_matrix, distortion_coeffs = distortion_coeffs):\n",
    "    '''\n",
    "    This function takes the distorted image and returns the undistorted version of it by \n",
    "    passing, camera matrix and distortion coefficients calculated by images in /camera_cal \n",
    "    directory, to the cv2.undistort.\n",
    "    '''\n",
    "    return cv2.undistort(img, camera_matrix, distortion_coeffs, None, camera_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Undistorting a distorted image\n",
    "\n",
    "distorted_image = mpimg.imread('camera_cal/calibration1.jpg')\n",
    "undistorted_image = undistort(distorted_image)\n",
    "\n",
    "\n",
    "_ = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.set_title('Distorted Image')\n",
    "ax1.imshow(distorted_image)\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.set_title('Undistorted Image')\n",
    "ax2.imshow(undistorted_image)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding\n",
    "\n",
    "In this section we'll use multiple thresholding techniques like Absolute-Sobel thresholding, Magnitude-Sobel thresholding, Directional-Sobel thresholding, Color thresholding in RGB and HLS color spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def abs_sobel_threshold(img, orient='x', thresh_min=0, thresh_max=255, sobel_kernel=3):\n",
    "    '''\n",
    "    This function computes absolute sobel threshold of the given image\n",
    "    '''\n",
    "    \n",
    "    # If image is colorful, then convert it into grayscale\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = img\n",
    "        \n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "    \n",
    "    # Scaling    \n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    \n",
    "    # Applying Thresholds\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "\n",
    "def mag_sobel_threshold(img, thresh_min=0, thresh_max=255, sobel_kernel=3):\n",
    "    '''\n",
    "    This function computes magnitude sobel threshold of the given image\n",
    "    '''\n",
    "    \n",
    "    # If image is colorful, then convert it into grayscale\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = img\n",
    "\n",
    "    # Computing gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    # Computing gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    \n",
    "    # Scaling\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "\n",
    "    # Applying Thresholds\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= thresh_min) & (gradmag <= thresh_max)] = 1\n",
    "\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "def dir_sobel_threshold(img, thresh_min=0, thresh_max=np.pi/2, sobel_kernel=3):\n",
    "    '''\n",
    "    This function computes directional sobel threshold of the given image\n",
    "    '''\n",
    "    \n",
    "    # If image is colorful, then convert it into grayscale\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = img\n",
    "    \n",
    "    # Computing gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    # Computing gradient direction\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    \n",
    "    # Applying Thresholds\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh_min) & (absgraddir <= thresh_max)] = 1\n",
    "\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "def single_channel_threshold(img, channnel_num, thresh_min=0, thresh_max=255):\n",
    "    '''\n",
    "    This function takes a multichannel image and applies thresholds to the provided channel\n",
    "    '''\n",
    "    channel = img[:,:,channnel_num]\n",
    "    output = np.zeros_like(channel)\n",
    "    output[(channel > thresh_min) & (channel <= thresh_max)] = 1\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Applying all the above thresholding techniques to a sample image\n",
    "\n",
    "image = mpimg.imread('test_images/test2.jpg')\n",
    "\n",
    "HLS_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "sobelX = abs_sobel_threshold(image, 'x', 10, 200)\n",
    "sobelY = abs_sobel_threshold(image, 'y', 10, 200)\n",
    "sobel_mag = mag_sobel_threshold(image, 50, 200)\n",
    "sobel_dir = dir_sobel_threshold(image, 0.7, 1.3)\n",
    "\n",
    "R = single_channel_threshold(image, 0, 150, 255)\n",
    "G = single_channel_threshold(image, 1, 150, 255)\n",
    "B = single_channel_threshold(image, 2, 150, 255)\n",
    "\n",
    "H = single_channel_threshold(HLS_image, 0, 120, 150)\n",
    "L = single_channel_threshold(HLS_image, 1, 120, 255)\n",
    "S = single_channel_threshold(HLS_image, 2, 100, 255)\n",
    "\n",
    "\n",
    "_ = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "plt.title('Original Image')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "_ = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "ax1 = plt.subplot(221)\n",
    "ax1.set_title('SobelX Threshold')\n",
    "ax1.imshow(sobelX, cmap='gray')\n",
    "\n",
    "ax2 = plt.subplot(222)\n",
    "ax2.set_title('SobelY Threshold')\n",
    "ax2.imshow(sobelY, cmap='gray')\n",
    "\n",
    "ax3 = plt.subplot(223)\n",
    "ax3.set_title('Sobel Magnitude Threshold')\n",
    "ax3.imshow(sobel_mag, cmap='gray')\n",
    "\n",
    "ax4 = plt.subplot(224)\n",
    "ax4.set_title('Sobel Direction Threshold')\n",
    "ax4.imshow(sobel_dir, cmap='gray')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "_ = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "ax1 = plt.subplot(231)\n",
    "ax1.set_title('R Channel Threshold')\n",
    "ax1.imshow(R, cmap='gray')\n",
    "\n",
    "ax2 = plt.subplot(232)\n",
    "ax2.set_title('G Channel Threshold')\n",
    "ax2.imshow(G, cmap='gray')\n",
    "\n",
    "ax3 = plt.subplot(233)\n",
    "ax3.set_title('B Channel Threshold')\n",
    "ax3.imshow(B, cmap='gray')\n",
    "\n",
    "ax4 = plt.subplot(234)\n",
    "ax4.set_title('H Channel Threshold')\n",
    "ax4.imshow(H, cmap='gray')\n",
    "\n",
    "ax5 = plt.subplot(235)\n",
    "ax5.set_title('L Channel Threshold')\n",
    "ax5.imshow(L, cmap='gray')\n",
    "\n",
    "ax6 = plt.subplot(236)\n",
    "ax6.set_title('S Channel Threshold')\n",
    "ax6.imshow(S, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Thresholds\n",
    "\n",
    "In this section, we will combine multiple thresholding techniques in a way that it will be able to identify both yellow and white road lane lines efficiently in an image. We will take advantages to the facts that, R & G channels in RGB color space, S channel in HLS space along with SobelX can determine road lane lines efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def combined_threshold(img):\n",
    "    '''\n",
    "    This function applies threshold to an image in order to identify road lane lines efficiently\n",
    "    '''\n",
    "    \n",
    "    # converting image to grayscale and HLS\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    HLS_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    \n",
    "    # Calculating thresholds by all techniques\n",
    "    sobelX = abs_sobel_threshold(gray, 'x', 10, 200)\n",
    "    sobelY = abs_sobel_threshold(gray, 'y', 10, 200)\n",
    "    sobel_mag = mag_sobel_threshold(gray, 10, 200)\n",
    "    sobel_dir = dir_sobel_threshold(gray, 0.7, 1.3)\n",
    "\n",
    "    R = single_channel_threshold(img, 0, 150, 255)\n",
    "    G = single_channel_threshold(img, 1, 150, 255)\n",
    "    B = single_channel_threshold(image, 2, 150, 255)\n",
    "\n",
    "    H = single_channel_threshold(HLS_image, 0, 100, 255)\n",
    "    L = single_channel_threshold(HLS_image, 1, 100, 255)\n",
    "    S = single_channel_threshold(HLS_image, 2, 100, 255) \n",
    "    \n",
    "    # For Sobel Threhold we will consider absolute sobel in X direction as whenever road lanes lines\n",
    "    # appear in an image, its gradient in x direction abruptly changes. So we will combine sobelX and sobel_dir\n",
    "    sobel_threshold = (sobelX == 1) & (sobel_dir == 1)\n",
    "    \n",
    "    # For color threshold we will choose channel R and G as they detect yellow lanes. We will consider R and G\n",
    "    # channels only when there is ample lightness\n",
    "    color_threshold = (R == 1) & (G == 1) & (L == 1)\n",
    "    \n",
    "    # S channel appears to detect both yellow and white lanes with highest efficiency even in varying lighting conditions\n",
    "    hls_threshold   = (S == 1) \n",
    "    \n",
    "    output = np.zeros_like(H)\n",
    "    \n",
    "    # for the final combination of thresholds, either saturation or gradients must be present along with R and G channels\n",
    "    output[color_threshold & (hls_threshold | sobel_threshold)] = 1\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "def get_roi_vertices(X=1280, Y=720, top_left_offset=550, top_right_offset=550, bottom_left_offset=120, bottom_right_offset=120):\n",
    "    '''\n",
    "    This function computes vertices of the area of interest on the basis of provided offset.\n",
    "    NOTE: it only focuses on bottom 40% of the image\n",
    "    '''\n",
    "    return np.array([[(bottom_left_offset,Y),\n",
    "                      (top_left_offset, 0.6*Y),\n",
    "                      (X-top_right_offset, 0.6*Y), \n",
    "                      (X-bottom_right_offset, Y)]], dtype=np.int32)\n",
    "\n",
    "\n",
    "def region_of_interest(img, vertices = get_roi_vertices()):\n",
    "    '''\n",
    "    This function returns area of interest in an image based on provided vertices\n",
    "    '''\n",
    "    \n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]\n",
    "        color = (255,) * channel_count\n",
    "    else:\n",
    "        color = 255\n",
    "        \n",
    "    cv2.fillPoly(mask, vertices, color)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Applying combined threshold and getting area of interest for a sample image\n",
    "\n",
    "img = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "thresh = combined_threshold(img)\n",
    "thresh_roi = region_of_interest(thresh)\n",
    "\n",
    "_ = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "ax1 = plt.subplot(131)\n",
    "ax1.set_title('Sample Image')\n",
    "ax1.imshow(img)\n",
    "\n",
    "ax2 = plt.subplot(132)\n",
    "ax2.set_title('Thresholded Image')\n",
    "ax2.imshow(thresh, cmap='gray')\n",
    "\n",
    "ax3 = plt.subplot(133)\n",
    "ax3.set_title('Thresholded Region of Interest')\n",
    "ax3.imshow(thresh_roi, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Perspective Transform\n",
    "\n",
    "In this section, we will compute top view (Birs's eye view) of the lane so that we can calculate radius of curvature of the lanes, which will eventually help us in finding steering angle and other useful information. \n",
    "To get this perspective transform, first, we will take a sample image which has straight road lanes and we will manually choose 4 points in the image whose transformed coordinates we can calculate. Then, we will use **cv2.getPerspectiveTransform** to get  transform matrix and inverse transform matrix. Finally, we can warp and unwarp the perspective by using transform matrix and inverse transform matrix along with **cv2.warpPerspective**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/straight_lines2.jpg') # sample image with straight road lanes\n",
    "undistorted_img = undistort(img)\n",
    "thresholded_img = region_of_interest(combined_threshold(undistorted_img))\n",
    "\n",
    "# Manually chosen points on source\n",
    "src = np.array([[295,665],[415,580],[892,580],[1024,665]], np.float32)\n",
    "\n",
    "# Manually calculted points for the destination\n",
    "dst = np.array([[295,665],[295,580],[1024,580],[1024,665]], np.float32)\n",
    "\n",
    "# Plotting polygon around the chosen points\n",
    "cv2.polylines(undistorted_img, np.array([src], np.int32), True, (255,0,0), 10)\n",
    "\n",
    "# Calculating transformation matrix and inverse transformation matrix\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "M_ = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "# Warping perspective using transformation matrix with cv2.warpPerspective\n",
    "warped_img = cv2.warpPerspective(thresholded_img, M, thresholded_img.shape[::-1] , flags=cv2.INTER_LINEAR)\n",
    "\n",
    "_ = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "ax1 = plt.subplot(131)\n",
    "ax1.set_title('Sample Image')\n",
    "ax1.imshow(undistorted_img)\n",
    "\n",
    "ax2 = plt.subplot(132)\n",
    "ax2.set_title('Thresholded Image')\n",
    "ax2.imshow(thresholded_img, cmap='gray')\n",
    "\n",
    "ax3 = plt.subplot(133)\n",
    "ax3.set_title('Warped Image')\n",
    "ax3.imshow(warped_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def warped(thresholded_image):\n",
    "    '''\n",
    "    This function warps prespective of an image from front view to bird's eye view by using transformation matrix calculated\n",
    "    earlier\n",
    "    '''\n",
    "    return cv2.warpPerspective(thresholded_image, M, thresholded_image.shape[::-1] , flags=cv2.INTER_NEAREST)\n",
    "\n",
    "def unwarped(color_warp):\n",
    "    '''\n",
    "    This function warps prespective of an image from  bird's eye to front view view by using inverse transformation matrix \n",
    "    calculated earlier.\n",
    "    NOTE: This function takes colorful warped images as argument\n",
    "    '''\n",
    "    return cv2.warpPerspective(color_warp, M_, color_warp.shape[::-1][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Warping a sample image\n",
    "\n",
    "img = mpimg.imread('test_images/test3.jpg')\n",
    "undistorted_img = undistort(img)\n",
    "thresholded_img = region_of_interest(combined_threshold(undistorted_img))\n",
    "warped_img = warped(thresholded_img)\n",
    "\n",
    "_ = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "ax1 = plt.subplot(131)\n",
    "ax1.set_title('Sample Image')\n",
    "ax1.imshow(undistorted_img)\n",
    "\n",
    "ax2 = plt.subplot(132)\n",
    "ax2.set_title('Thresholded Image')\n",
    "ax2.imshow(thresholded_img, cmap='gray')\n",
    "\n",
    "ax3 = plt.subplot(133)\n",
    "ax3.set_title('Warped Image')\n",
    "ax3.imshow(warped_img, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lane Detection\n",
    "\n",
    "In this section we will find out pixels corresponding to the lane lines in a binary warped image. To find lane pixels we will first plot histogram histogram along all the columns in the lower half of the image. With this histogram we are adding up the pixel values along each column in the image. In our thresholded binary image, pixels are either 0 or 1, so the two most prominent peaks in this histogram will be good indicators of the x-position of the base of the lane lines. We can use that as a starting point for where to search for the lines. From that point, we can use a sliding window, placed around the line centers, to find and follow the lines up to the top of the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_lane_pixels(binary_warped):\n",
    "    \n",
    "    # Calculating histogram along all coulumns in lower half of the binary warped image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "\n",
    "    # Calculating possible x coordinates to start finding lane lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Hyperparameters\n",
    "    nwindows = 9\n",
    "    margin = 100\n",
    "    minpix = 50\n",
    "\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    \n",
    "    # Finding activated indices\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # performing sliding window\n",
    "    for window in range(nwindows):\n",
    "        \n",
    "        # Calculating corner points for the left and right windows\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Drawing left and right window\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        # Filtering out activated indices\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    # Calculating activated points\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img, histogram\n",
    "\n",
    "\n",
    "def fit_polynomial(binary_warped):\n",
    "    '''\n",
    "    This function fits 2 degree polynomial to road lanes detected in the given binary warped image\n",
    "    '''\n",
    "    \n",
    "    # Calulates activated right an left lane pixels\n",
    "    leftx, lefty, rightx, righty, out_img, histogram = find_lane_pixels(binary_warped)\n",
    "\n",
    "    # Fitting the curve\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Plotting the curve\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    out_img[ploty.astype(np.int), left_fitx.astype(np.int)]   = [255, 255, 0]\n",
    "    out_img[ploty.astype(np.int), right_fitx.astype(np.int)]  = [255, 255, 0]    \n",
    "\n",
    "    return left_fit, right_fit, histogram, out_img, (leftx,lefty,rightx,righty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting Histogram and detecting lane for a previously calculated sample warped image\n",
    "\n",
    "left_fit, right_fit, histogram, out_img,_ = fit_polynomial(warped_img)\n",
    "\n",
    "midpoint = np.int(histogram.shape[0]//2)\n",
    "leftx_base = np.argmax(histogram[:midpoint])\n",
    "rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "plt.show()\n",
    "\n",
    "_ = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "ax1 = plt.subplot(1,2,1)\n",
    "ax1.set_title('Histogram of lower half of the image')\n",
    "ax1.plot(histogram)\n",
    "ax1.scatter(x=[leftx_base,rightx_base], y =[histogram[leftx_base],histogram[rightx_base]], marker='s', c='red', linewidth=5)\n",
    "\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "ax2.set_title('Detected Lanes')\n",
    "ax2.imshow(out_img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search around previous detected lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_poly(img_shape, leftx, lefty, rightx, righty):\n",
    "    '''\n",
    "    This function fits a 2 degree polynomial to left and right activated pixels of a binary warped image\n",
    "    '''\n",
    "    \n",
    "    # Fitting curve\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Calculating plotting points\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    return left_fitx, right_fitx, ploty, left_fit, right_fit\n",
    "\n",
    "def search_around_poly(binary_warped, left_fit_prev, right_fit_prev):\n",
    "    '''\n",
    "    This function takes a binary warped image of road lanes and fits 2 degree polynomial to the left lane and right\n",
    "    lane on the basis of detected lanes and previously detected lanes\n",
    "    '''\n",
    "\n",
    "    margin = 100\n",
    "\n",
    "    # Calculating activated indices\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Calculating lane indices\n",
    "    left_lane_inds = ((nonzerox > (left_fit_prev[0]*(nonzeroy**2) + left_fit_prev[1]*nonzeroy + \n",
    "                    left_fit_prev[2] - margin)) & (nonzerox < (left_fit_prev[0]*(nonzeroy**2) + \n",
    "                    left_fit_prev[1]*nonzeroy + left_fit_prev[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit_prev[0]*(nonzeroy**2) + right_fit_prev[1]*nonzeroy + \n",
    "                    right_fit_prev[2] - margin)) & (nonzerox < (right_fit_prev[0]*(nonzeroy**2) + \n",
    "                    right_fit_prev[1]*nonzeroy + right_fit_prev[2] + margin)))\n",
    "    \n",
    "    # calculating activated lane points\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    # Fitting the curve\n",
    "    left_fitx, right_fitx, ploty, lfit, rfit = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "    \n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    \n",
    "    # plotting lane pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    \n",
    "    result[ploty.astype(np.int), left_fitx.astype(np.int)]   = [255, 255, 0]\n",
    "    result[ploty.astype(np.int), right_fitx.astype(np.int)]  = [255, 255, 0]\n",
    "\n",
    "    return lfit, rfit, result, (leftx,lefty,rightx,righty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fitting curve on a sample binary warped image basis of given previously detected lines\n",
    "\n",
    "left_fit_prev  = np.array([ 2.13935315e-04, -3.77507980e-01,  4.76902175e+02])\n",
    "right_fit_prev = np.array([4.17622148e-04, -4.93848953e-01,  1.11806170e+03])\n",
    "\n",
    "_, _, result, coordinates = search_around_poly(warped_img, left_fit_prev, right_fit_prev)\n",
    "\n",
    "_ = plt.subplots(figsize=(20, 10))\n",
    "plt.imshow(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring radius of curvature and center offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def measure_curvature_real(img_shape, left_fit_cr, right_fit_cr, xm_per_pix = 3.7/700, ym_per_pix = 30/720):\n",
    "    '''\n",
    "    This function calculates radius of curvature of left ang right road lanes in a binary warped image\n",
    "    given curve equation of both the lanes\n",
    "    '''\n",
    "    y_eval = img_shape[0]-1 # point in image where it will calculate radius of curvature\n",
    "    \n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "def measure_center_offset_real(img_shape, left_fit_cr, right_fit_cr, xm_per_pix = 3.7/700):\n",
    "    '''\n",
    "    This function calculates offset from the center of the road lanes in a binary warped image\n",
    "    given curve equation of both the lanes\n",
    "    '''    \n",
    "    y_eval = img_shape[0]-1 # point in image where it will calculate center offset\n",
    "    \n",
    "    lane_left_x = left_fit_cr[0]*y_eval**2 + left_fit_cr[1]*y_eval + left_fit_cr[2]\n",
    "    lane_right_x = right_fit_cr[0]*y_eval**2 + right_fit_cr[1]*y_eval + right_fit_cr[2]\n",
    "    lane_center_x = (lane_left_x + lane_right_x)//2\n",
    "    \n",
    "    image_center_x = img_shape[1]//2\n",
    "    \n",
    "    return (image_center_x - lane_center_x)*xm_per_pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculating radius of curvature and center offset for previosly calculated sample binary warped image\n",
    "\n",
    "left_fit, right_fit, histogram, out_img,_ = fit_polynomial(warped_img)\n",
    "left_curverad, right_curverad = measure_curvature_real(out_img.shape, left_fit, right_fit)\n",
    "offset = measure_center_offset_real(out_img.shape, left_fit, right_fit)\n",
    "\n",
    "print('Left line curvature:', left_curverad, 'm')\n",
    "print('Right line curvature:', right_curverad, 'm')\n",
    "print('Center offset:', offset, 'm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing Lanes and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_lane(img, warped_img, left_fit, right_fit, coordinates):\n",
    "    '''\n",
    "    This function draws lane on `img` using `warped_img`, `left_fit` and, `right_fit`\n",
    "    '''\n",
    "    # defining empty colored image\n",
    "    warp = np.zeros_like(warped_img).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp, warp, warp))\n",
    "\n",
    "    # Calculating lane pixels\n",
    "    ploty = np.linspace(0, warped_img.shape[0]-1, warped_img.shape[0])\n",
    "    pts_left_x = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    pts_right_x = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    pts_left = np.vstack([pts_left_x.astype(np.int),ploty.astype(np.int)]).transpose()\n",
    "    pts_right = np.vstack([pts_right_x.astype(np.int),ploty.astype(np.int)]).transpose()\n",
    "    pts = np.vstack([pts_left,np.flipud(pts_right)])\n",
    "\n",
    "    # plotting green polygon on lane\n",
    "    cv2.fillPoly(color_warp, [pts], (0,255, 0))\n",
    "    \n",
    "    # plotting lane pixels\n",
    "    for center in zip(coordinates[0],coordinates[1]):\n",
    "        cv2.circle(color_warp,center, 5, (255,0,0), 5)\n",
    "    for center in zip(coordinates[2],coordinates[3]):\n",
    "        cv2.circle(color_warp,center, 5, (0,0,255), 5)\n",
    "    \n",
    "    # unwarping image\n",
    "    unwarped_img = unwarped(color_warp)\n",
    "    \n",
    "    # merging detected lane image with actual image\n",
    "    weighted_img = cv2.addWeighted(img, 1, unwarped_img, 0.3, 0)\n",
    "    \n",
    "    return weighted_img \n",
    "\n",
    "def draw_metrics(img, left_fit, right_fit, xm_per_pix = 3.7/700, ym_per_pix = 30/720):\n",
    "    '''\n",
    "    This function draws radius of curvature and offset on `img`\n",
    "    '''\n",
    "    left_curverad, right_curverad = measure_curvature_real(img.shape, left_fit, right_fit, xm_per_pix, ym_per_pix)\n",
    "    offset = measure_center_offset_real(img.shape, left_fit, right_fit, xm_per_pix)\n",
    "    \n",
    "    curverad = 'Radius of Curvature =  %d(m)'%min(left_curverad,right_curverad)\n",
    "    if offset < 0:\n",
    "        offset = 'Vehicle is %.2fm left of center'%abs(offset)\n",
    "    else:\n",
    "        offset = 'Vehicle is %.2fm right of center'%offset\n",
    "        \n",
    "    cv2.putText(img,curverad,(50,80), cv2.FONT_HERSHEY_SIMPLEX, 2,(255,255,255),3,cv2.LINE_AA)\n",
    "    cv2.putText(img,offset,(50,160), cv2.FONT_HERSHEY_SIMPLEX, 2,(255,255,255),3,cv2.LINE_AA)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drawing lanes and metrics on a sample image\n",
    "\n",
    "img_lane = draw_lane(undistorted_img, warped_img, left_fit, right_fit, coordinates)\n",
    "img_lane_metric = draw_metrics(img_lane, left_fit, right_fit)\n",
    "\n",
    "_ = plt.subplots(figsize=(20, 10))\n",
    "plt.imshow(img_lane_metric)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "In this section we will combine all the above impelemented functions in order to generate end to end pipeline \n",
    "to get annotated image with detected lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deque_maxlen = 10  # smoothen over this many frames  \n",
    "prev_detected_lines = deque(maxlen=deque_maxlen) # GLOBAL variable used in smoothen_lines\n",
    "\n",
    "def smoothen_lines(left_line, right_line):\n",
    "    '''\n",
    "    This function smoothens the detected lines using `prev_detected_lines`\n",
    "    '''\n",
    "    global prev_detected_lines\n",
    "    \n",
    "    if (left_line is None) or (right_line is None):\n",
    "        if prev_detected_lines:\n",
    "            # If pipeline fails to detec line, returns previous detected line\n",
    "            return prev_detected_lines[-1][0], prev_detected_lines[-1][1]\n",
    "        return None, None\n",
    "    \n",
    "    if len(prev_detected_lines) < deque_maxlen:\n",
    "        # if previously detected line buffer isn't full add current detected line in the buffer\n",
    "        prev_detected_lines.append((left_line, right_line))\n",
    "        return left_line, right_line\n",
    "    \n",
    "    # If line buffer is full returns the averaged line\n",
    "    prev_detected_lines.append((left_line, right_line))\n",
    "    left_smoothened, right_smoothened = [sum(i)/deque_maxlen for i in zip(*prev_detected_lines)]\n",
    "    return left_smoothened, right_smoothened\n",
    "\n",
    "\n",
    "\n",
    "left_fit_prev, right_fit_prev = None, None # GLOBAL variables used in pipeline\n",
    "\n",
    "def pipeline(img, smoothening=True, search_around_previous_detections = True):\n",
    "    '''\n",
    "    This function is end to end pipeline to get annotated image of detected lanes\n",
    "    '''\n",
    "    global left_fit_prev, right_fit_prev\n",
    "\n",
    "    try:\n",
    "        # Step 1: Undistort the image\n",
    "        undistorted_image = undistort(img)\n",
    "        \n",
    "        # Step 2: Threshold the image\n",
    "        thresholded_image = combined_threshold(undistorted_image)\n",
    "        \n",
    "        # Step 3: Get area of interest\n",
    "        thresholded_image_roi = region_of_interest(thresholded_image)\n",
    "        \n",
    "        # Step 4: Compute bird's eye view \n",
    "        warped_image = warped(thresholded_image_roi)\n",
    "        \n",
    "        # Step 5: Detect lane Lines\n",
    "        if search_around_previous_detections:\n",
    "            try:\n",
    "                # Search around previously detected lines\n",
    "                left_fit, right_fit, _, coordinates = search_around_poly(warped_image, left_fit_prev, right_fit_prev)\n",
    "                left_fit_prev, right_fit_prev = left_fit, right_fit\n",
    "            except:\n",
    "                try:\n",
    "                    # Search from scratch by histogram method\n",
    "                    left_fit, right_fit, _, _, coordinates = fit_polynomial(warped_image)\n",
    "                    left_fit_prev, right_fit_prev = left_fit, right_fit\n",
    "                except:\n",
    "                    left_fit, right_fit = None, None\n",
    "\n",
    "            if smoothening:\n",
    "                # Smoothen over past frames\n",
    "                left_fit, right_fit = smoothen_lines(left_fit, right_fit)\n",
    "        else:\n",
    "            # Search from scratch by histogram method\n",
    "            left_fit, right_fit, _, _, coordinates = fit_polynomial(warped_image)\n",
    "        \n",
    "        # Step 6: Draw lanes\n",
    "        img_lane = draw_lane(undistorted_image, warped_image, left_fit, right_fit, coordinates)\n",
    "        \n",
    "        # Step 7: Draw metrics\n",
    "        out_img = draw_metrics(img_lane, left_fit, right_fit)\n",
    "        return out_img\n",
    "    except:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run end to end pipeline on test images\n",
    "\n",
    "test_images = glob('test_images/*jpg')\n",
    "\n",
    "_ = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "for i in range(len(test_images)):\n",
    "    \n",
    "    im_path = test_images[i]\n",
    "    img = plt.imread(im_path)\n",
    "    out = pipeline(img, False, False)\n",
    "    \n",
    "    plt.imsave(im_path.replace('test_images','output_images'), out)\n",
    "    \n",
    "    ax = plt.subplot(4,2,i+1)\n",
    "    ax.set_title(im_path)\n",
    "    ax.imshow(out)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotating Project Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = 'project_video_output.mp4'\n",
    "clip = VideoFileClip('project_video.mp4')\n",
    "\n",
    "prev_detected_lines = deque(maxlen=deque_maxlen)\n",
    "left_fit_prev, right_fit_prev = None, None\n",
    "\n",
    "clip = clip.fl_image(pipeline)\n",
    "clip.write_videofile(output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotating Challenge Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = 'challenge_video_output.mp4'\n",
    "clip = VideoFileClip('challenge_video.mp4')\n",
    "\n",
    "prev_detected_lines = deque(maxlen=deque_maxlen)\n",
    "left_fit_prev, right_fit_prev = None, None\n",
    "\n",
    "clip = clip.fl_image(pipeline)\n",
    "clip.write_videofile(output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotating Harder Challenge Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = 'harder_challenge_video_output.mp4'\n",
    "clip = VideoFileClip('harder_challenge_video.mp4')\n",
    "\n",
    "prev_detected_lines = deque(maxlen=deque_maxlen)\n",
    "left_fit_prev, right_fit_prev = None, None\n",
    "\n",
    "clip = clip.fl_image(pipeline)\n",
    "clip.write_videofile(output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda35]",
   "language": "python",
   "name": "conda-env-Anaconda35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
